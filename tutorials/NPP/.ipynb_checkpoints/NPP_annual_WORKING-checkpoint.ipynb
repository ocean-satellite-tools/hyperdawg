{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "821bbdf5-50ee-483f-9592-009731157d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====== Processing Year 2022 ======\n",
      "\n",
      "Region 1, 2022: 20,129,302,254,075.90 g C / y in 1.5 sec\n",
      "Region 2, 2022: 207,134,274,012,177.56 g C / y in 1.4 sec\n",
      "Region 3, 2022: 1,172,391,733,629,958.75 g C / y in 10.0 sec\n",
      "Region 4, 2022: 277,895,397,183,491.41 g C / y in 1.3 sec\n",
      "Region 5, 2022: 94,795,431,906,285.45 g C / y in 1.2 sec\n",
      "Region 6, 2022: 404,924,552,670,218.00 g C / y in 16.5 sec\n",
      "Region 7, 2022: 89,606,961,989,699.67 g C / y in 1.1 sec\n",
      "Region 8, 2022: 102,068,711,871,641.78 g C / y in 0.9 sec\n",
      "\n",
      "✅ Exported results to npp_by_region_and_year.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import urllib.request \n",
    "import xarray as xr \n",
    "import regionmask\n",
    "import geopandas as gpd\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Load shapefile\n",
    "gdf = gpd.read_file(\"20210609_fishery_management_council_regions.shp\")\n",
    "\n",
    "# Constants\n",
    "pixel_area_m2 = 9_000 ** 2  # m²\n",
    "all_results = []\n",
    "\n",
    "# Loop through years\n",
    "for year in range(2022, 2023):\n",
    "    print(f\"\\n====== Processing Year {year} ======\\n\")\n",
    "    tcoord = (f\"{year}-01-15\", f\"{year}-12-15\")\n",
    "\n",
    "    for idx in range(len(gdf)):\n",
    "        t0 = time.time()\n",
    "        polygon = gdf.loc[idx, \"geometry\"]\n",
    "        \n",
    "        # Get bounds and clip\n",
    "        minx, miny, maxx, maxy = polygon.bounds\n",
    "        minx = max(minx, -179.91667)\n",
    "        maxx = min(maxx, 179.91667)\n",
    "        miny = max(miny, -89.9792)\n",
    "        maxy = min(maxy, 89.9792)\n",
    "\n",
    "        # Sort for ERDDAP\n",
    "        lat_start = max(miny, maxy)\n",
    "        lat_end   = min(miny, maxy)\n",
    "        lon_start = min(minx, maxx)\n",
    "        lon_end   = max(minx, maxx)\n",
    "\n",
    "        assert lon_start >= -180 and lon_end <= 180\n",
    "\n",
    "        # Create the URL\n",
    "        url = (\n",
    "            f\"https://erddap.marine.usf.edu/erddap/griddap/moda_npp_mo_glob.nc?\"\n",
    "            f\"npp[({tcoord[0]}):1:({tcoord[1]})]\"\n",
    "            f\"[({lat_start}):1:({lat_end})]\"\n",
    "            f\"[({lon_start}):1:({lon_end})]\"\n",
    "        )\n",
    "\n",
    "        filename = f\"npp_region_{idx+1}_{year}.nc\"\n",
    "        try:\n",
    "            urllib.request.urlretrieve(url, filename)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to download for Region {idx+1}, {year}: {e}\")\n",
    "            continue\n",
    "\n",
    "        # Load data\n",
    "        ds = xr.open_dataset(filename, decode_cf=False)\n",
    "        npp = ds['npp']\n",
    "        lats = ds.latitude.values\n",
    "        lons = ds.longitude.values\n",
    "\n",
    "        # Create 2D lat/lon grid\n",
    "        lon2d, lat2d = np.meshgrid(lons, lats)\n",
    "\n",
    "        # Rasterize mask using regionmask (shape: lat x lon)\n",
    "        region = regionmask.Regions([polygon])\n",
    "        mask_2d = region.mask(lon2d, lat2d).values\n",
    "        mask_2d = np.where(np.isnan(mask_2d), np.nan, 1.0)\n",
    "\n",
    "        # Broadcast mask to time dimension (time x lat x lon)\n",
    "        mask_3d = np.broadcast_to(mask_2d, npp.shape)\n",
    "\n",
    "        # Apply mask early\n",
    "        npp_masked = npp.where(mask_3d == 1)\n",
    "\n",
    "        # Use actual time from file to avoid mismatch\n",
    "        time_vals = pd.to_datetime(npp['time'].values)\n",
    "        days_in_month = np.array([t.days_in_month for t in time_vals])\n",
    "        days_da = xr.DataArray(days_in_month, coords={'time': npp['time']}, dims='time')\n",
    "\n",
    "        # Weighted sum\n",
    "        npp_weighted = npp_masked * days_da\n",
    "        npp_sum = npp_weighted.sum(dim='time')\n",
    "\n",
    "        # Final area-based NPP\n",
    "        total_npp = np.nansum(npp_sum.values) / 1000\n",
    "        total_npp2 = total_npp * pixel_area_m2\n",
    "\n",
    "        all_results.append({\n",
    "            \"year\": year,\n",
    "            \"region\": f\"Region_{idx+1}\",\n",
    "            \"npp_gC_per_year\": total_npp2\n",
    "        })\n",
    "\n",
    "        print(f\"Region {idx+1}, {year}: {total_npp2:,.2f} g C / y in {time.time() - t0:.1f} sec\")\n",
    "\n",
    "        ds.close()\n",
    "        os.remove(filename)\n",
    "\n",
    "# Convert to DataFrame and export\n",
    "df_results = pd.DataFrame(all_results)\n",
    "df_results.to_csv(\"npp_by_region_and_year.csv\", index=False)\n",
    "print(\"\\n✅ Exported results to npp_by_region_and_year.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cc8397-3956-4ad1-af5e-a67678a9789b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
