{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93c7f82f-34b6-4562-b775-d45c6783ec84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unauthorized access. Please check your Earthdata credentials.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/368 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e78eaeda430e41c5b9c7f434f22e6448",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db72599e8c6a4f6eae7fb4d5f7802056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10aaa2ef1574f07b114ccfc48ddeccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9360be8623ee40cf89c3ce8af789de20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QUEUEING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7fdd33f17141f08ce5c986267a74c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "PROCESSING TASKS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd949aea3b434080bde86297126dc474",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "COLLECTING RESULTS | :   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/368 [00:54<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "download_sst_data() missing 2 required positional arguments: 'earthdata_username' and 'earthdata_password'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 104\u001b[0m\n\u001b[1;32m    101\u001b[0m ds_avw \u001b[38;5;241m=\u001b[39m load_cached_dataset(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPACE_OCI_L3M_AVW\u001b[39m\u001b[38;5;124m\"\u001b[39m, start_date, end_date, avw_cache)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# === Download MODIS Aqua SST data ===\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m ds_sst \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_sst_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstart_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_date\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ds_rrs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ds_avw \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m ds_sst \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    107\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSkipping \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtow_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m due to missing datasets.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: download_sst_data() missing 2 required positional arguments: 'earthdata_username' and 'earthdata_password'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from datetime import datetime\n",
    "import earthaccess\n",
    "from tqdm import tqdm\n",
    "\n",
    "# === Authenticate ===\n",
    "auth = earthaccess.login()\n",
    "assert auth.authenticated, \"Earthaccess login failed.\"\n",
    "\n",
    "# === Load simplified catch data ===\n",
    "df = pd.read_csv(\"simplified_catch_summary.csv\")\n",
    "\n",
    "# === Helper: convert date to 8-day PACE period ===\n",
    "def get_8day_range(date_str):\n",
    "    dt = pd.to_datetime(date_str)\n",
    "    doy = (dt - pd.Timestamp(\"2024-01-01\")).days\n",
    "    start_day = 8 * (doy // 8)\n",
    "    start_date = pd.Timestamp(\"2024-01-01\") + pd.Timedelta(days=start_day)\n",
    "    end_date = start_date + pd.Timedelta(days=7)\n",
    "    return start_date.strftime(\"%Y-%m-%d\"), end_date.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "# === Caching logic ===\n",
    "rrs_cache = {}\n",
    "avw_cache = {}\n",
    "\n",
    "def load_cached_dataset(short_name, start_date, end_date, cache):\n",
    "    key = (short_name, start_date)\n",
    "    if key in cache:\n",
    "        return cache[key]\n",
    "    \n",
    "    results = earthaccess.search_data(\n",
    "        short_name=short_name,\n",
    "        temporal=(start_date, end_date),\n",
    "        granule_name=\"*.8D.*.4km.*\"\n",
    "    )\n",
    "    if not results:\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        ds = xr.open_dataset(earthaccess.open(results)[0])\n",
    "        cache[key] = ds\n",
    "        return ds\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to open dataset for {short_name} on {start_date}: {e}\")\n",
    "        return None\n",
    "\n",
    "# === Main loop ===\n",
    "rrs_data = []\n",
    "\n",
    "for _, row in tqdm(df.iterrows(), total=len(df)):\n",
    "    tow_date = row[\"TOWDATETIME_EST\"]\n",
    "    lat, lon = row[\"LAT\"], row[\"LON\"]\n",
    "    start_date, end_date = get_8day_range(tow_date)\n",
    "\n",
    "    # === Load datasets with caching ===\n",
    "    ds_rrs = load_cached_dataset(\"PACE_OCI_L3M_RRS\", start_date, end_date, rrs_cache)\n",
    "    ds_avw = load_cached_dataset(\"PACE_OCI_L3M_AVW\", start_date, end_date, avw_cache)\n",
    "\n",
    "    if ds_rrs is None or ds_avw is None:\n",
    "        print(f\"Skipping {tow_date} due to missing datasets.\")\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        # === Find nearest grid point ===\n",
    "        lat_idx = np.abs(ds_rrs[\"lat\"].values - lat).argmin()\n",
    "        lon_idx = np.abs(ds_rrs[\"lon\"].values - lon).argmin()\n",
    "\n",
    "        lat_slice = slice(max(lat_idx - 2, 0), min(lat_idx + 3, ds_rrs.sizes[\"lat\"]))\n",
    "        lon_slice = slice(max(lon_idx - 2, 0), min(lon_idx + 3, ds_rrs.sizes[\"lon\"]))\n",
    "\n",
    "        # === Rrs: mean over 5x5 box ===\n",
    "        rrs_vals = ds_rrs[\"Rrs\"][lat_slice, lon_slice, :].mean(dim=(\"lat\", \"lon\")).values\n",
    "        wavelengths = ds_rrs[\"wavelength\"].values\n",
    "\n",
    "        if np.all(np.isnan(rrs_vals)):\n",
    "            print(f\"All Rrs NaN for {tow_date}\")\n",
    "            continue\n",
    "\n",
    "        # === AVW: mean over 5x5 box ===\n",
    "        avw_val = ds_avw[\"avw\"][lat_slice, lon_slice].mean().item()\n",
    "\n",
    "        # === Store result ===\n",
    "        result = {\n",
    "            \"TOWDATETIME_EST\": tow_date,\n",
    "            \"AVW\": avw_val\n",
    "        }\n",
    "\n",
    "        for wl, val in zip(wavelengths, rrs_vals):\n",
    "            result[f\"Rrs_{int(wl)}\"] = val\n",
    "\n",
    "        rrs_data.append(result)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {tow_date} at {lat:.2f}, {lon:.2f} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "# === Merge with fisheries data and save ===\n",
    "rrs_df = pd.DataFrame(rrs_data)\n",
    "merged = pd.merge(df, rrs_df, on=\"TOWDATETIME_EST\", how=\"left\")\n",
    "merged.to_csv(\"fisheries_with_pace_rrs_avw.csv\", index=False)\n",
    "\n",
    "print(\"✅ Done! Output saved to: fisheries_with_pace_rrs_avw.csv\")\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Load the merged file\n",
    "df = pd.read_csv(\"fisheries_with_pace_rrs_avw.csv\")\n",
    "\n",
    "# --- Identify Rrs columns from 400 to 700 nm ---\n",
    "rrs_cols = [col for col in df.columns if col.startswith(\"Rrs_\")]\n",
    "\n",
    "# Extract wavelengths and keep only those between 400 and 700 nm\n",
    "rrs_wavelengths = [int(col.split(\"_\")[1]) for col in rrs_cols]\n",
    "rrs_filtered = [(wl, col) for wl, col in zip(rrs_wavelengths, rrs_cols) if 400 <= wl <= 700]\n",
    "\n",
    "# Sort by wavelength\n",
    "rrs_filtered.sort()\n",
    "wavelengths, rrs_ordered_cols = zip(*rrs_filtered)\n",
    "\n",
    "# Convert to NumPy array for vectorized integration\n",
    "rrs_values = df[list(rrs_ordered_cols)].values\n",
    "rrs_brightness = np.trapz(rrs_values, x=wavelengths, axis=1)\n",
    "\n",
    "# Add to DataFrame\n",
    "df[\"Rrs_brightness\"] = rrs_brightness\n",
    "\n",
    "# Save updated CSV\n",
    "df.to_csv(\"fisheries_with_pace_rrs_avw.csv\", index=False)\n",
    "\n",
    "print(\"✅ Added 'Rrs_brightness' and saved updated CSV.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a933d3-770b-43e8-8a87-9bf5923aca20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
